{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e241896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../../../\"))\n",
    "from enum import Enum\n",
    "from util.llm_client import LLMClient\n",
    "from util.chunker import Chunker\n",
    "import json\n",
    "import re\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8eb3730",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_client = LLMClient(json_format=True, temp=0.0)\n",
    "chunker = Chunker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3cf8d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileType(Enum):\n",
    "    WithoutChangelog = 1\n",
    "    Changelog = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e78d406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileAttributes:\n",
    "    def __init__(self, data_file: str, type: FileType, documentation: str, description: str, version: str, additional_attributes: list, category: str = None, document_id: str = None):\n",
    "        self.data_file = data_file\n",
    "        self.type = type\n",
    "        # documentation is a stable identifier used in the graph; prefer document_id if provided\n",
    "        self.documentation = document_id or documentation\n",
    "        self.display_name = documentation\n",
    "        self.description = description\n",
    "        self.version = version\n",
    "        self.additional_attributes = additional_attributes\n",
    "        self.category = category\n",
    "        \n",
    "    def __str__(self):\n",
    "        return (f\"File: {self.data_file}\\n\"\n",
    "                f\"File Type: {self.type.name}\\n\"\n",
    "                f\"Documentation: {self.documentation}\\n\"\n",
    "                f\"Display Name: {self.display_name}\\n\"\n",
    "                f\"Category: {self.category}\\n\"\n",
    "                f\"Description: {self.description}\\n\"\n",
    "                f\"Version: {self.version}\\n\"\n",
    "                f\"Additional Attributes:\\n\" +\n",
    "                (\n",
    "                    \"\\n\".join([f\"  - {attr}: {value}\" for attr, value in self.additional_attributes.items()])\n",
    "                    if self.additional_attributes else \"  - None\"\n",
    "                ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "30b89a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_attributes_from_file(data_file, category: str = None) -> FileAttributes:\n",
    "    print(f\"extract attributes from file {data_file}\")\n",
    "    # If category not provided, infer it from the parent folder name of the file.\n",
    "    # Example: data/raw/kalender-akademik/2024-2025.pdf -> category = \"kalender-akademik\"\n",
    "    if category is None:\n",
    "        file_dir = os.path.dirname(os.path.abspath(data_file))\n",
    "        inferred_category = os.path.basename(file_dir)\n",
    "        # If the file is directly under \"raw\", treat it as having no category.\n",
    "        category = None if inferred_category.lower() == \"raw\" else inferred_category\n",
    "    first_text_short = \"\"\n",
    "    first_text_long = \"\"\n",
    "    if data_file.lower().endswith(\".pdf\"):\n",
    "        # extract pages from pdf\n",
    "        page_count = get_page_count(data_file)\n",
    "        if page_count == 0:\n",
    "            raise ValueError(f\"file is empty: {data_file}\")\n",
    "        print(f\"page count {page_count}\")\n",
    "        \n",
    "        chunks = chunker.chunk_document(data_file=data_file, page_to=1)\n",
    "        first_text_short = \"\\n\".join(chunk.chunk for chunk in chunks if chunk.chunk)\n",
    "        chunks = chunker.chunk_document(data_file=data_file, page_to=min(page_count, 10))\n",
    "        first_text_long = \"\\n\".join(chunk.chunk for chunk in chunks if chunk.chunk)\n",
    "    elif data_file.lower().endswith(\".md\"):\n",
    "        # extract chunks from markdown\n",
    "        chunks = chunker.chunk_document(data_file=data_file)\n",
    "        chunk_count = len(chunks)\n",
    "        if chunk_count == 0:\n",
    "            raise ValueError(f\"file is empty: {data_file}\")\n",
    "        print(f\"chunk count {chunk_count}\")\n",
    "        # Kombiniere alle Chunks zu einem durchgehenden Text\n",
    "        full_text = \"\".join(chunk.chunk for chunk in chunks if chunk.chunk)\n",
    "\n",
    "        # Schneide die ersten 200 bzw. 500 Zeichen aus dem kombinierten Text\n",
    "        first_text_short = full_text[:200]\n",
    "        first_text_long = full_text[:300]\n",
    "    else:\n",
    "        raise ValueError(f'unsupported file type {data_file}')\n",
    "    \n",
    "    first_page_attributes = extract_attributes_from_first_page(first_text_short)\n",
    "    file_type = extract_file_type_from_pages(first_text_long)\n",
    "    \n",
    "    # Extract version from filename instead of from LLM\n",
    "    version_from_filename = extract_version_from_filename(data_file)\n",
    "    print(f\"Extracted version from filename: {version_from_filename}\")\n",
    "\n",
    "    return FileAttributes(data_file=data_file,\n",
    "                          type=file_type,\n",
    "                          documentation=first_page_attributes[\"topic\"],\n",
    "                          description=first_page_attributes[\"description\"],\n",
    "                          version=version_from_filename,\n",
    "                          additional_attributes=first_page_attributes.get(\"additional_attributes\"),\n",
    "                          category=category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7658dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_count(data_file):\n",
    "    with open(data_file, \"rb\") as file:\n",
    "        pdfReader = PyPDF2.PdfReader(file)\n",
    "        return len(pdfReader.pages)\n",
    "    raise ValueError(f\"unable to read page count from file: {data_file}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e801adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_version_string(version_str):\n",
    "    \"\"\"Keep only numbers, dashes, and dots from the version string.\"\"\"\n",
    "    return re.sub(r'[^0-9\\-.]', '', version_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "67f1ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_version_from_filename(data_file):\n",
    "    \"\"\"\n",
    "    Extract version from filename (without extension).\n",
    "    Examples:\n",
    "    - 2016-2017.pdf -> 2016-2017\n",
    "    - 2017-2018.pdf -> 2017-2018\n",
    "    - kalender-2024.pdf -> kalender-2024 (returns as-is if no clear pattern)\n",
    "    - file_v1.0.pdf -> file_v1.0 (returns as-is)\n",
    "    \n",
    "    Returns the filename without extension as the version.\n",
    "    \"\"\"\n",
    "    # Get filename without path and extension\n",
    "    filename = os.path.basename(data_file)\n",
    "    # Remove extension (.pdf, .md, etc.)\n",
    "    filename_without_ext = os.path.splitext(filename)[0]\n",
    "    \n",
    "    # Clean the version string (keep only alphanumeric, dashes, dots, underscores)\n",
    "    # This preserves formats like \"2016-2017\", \"v1.0\", \"2024\", etc.\n",
    "    cleaned_version = re.sub(r'[^a-zA-Z0-9\\-._]', '', filename_without_ext)\n",
    "    \n",
    "    return cleaned_version if cleaned_version else \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a7401d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_attributes_from_first_page(first_page_content):\n",
    "    system_prompt_first_page = \"\"\"\n",
    "    You are an intelligent assistant specialized in extracting structured information from documents.  \n",
    "    Your task is to analyze the first page of a given PDF and extract the following details in a structured JSON format. \n",
    "    Do not add JSON comments to the output.\n",
    "\n",
    "    1 **\"topic\"**: The main subject of the document.  \n",
    "    - Provide a short, clear, and descriptive title (max. 10 words).  \n",
    "    - Do not include any version reference in the title.\n",
    "    - If no clear topic is found, return `\"unknown\"`.  \n",
    "    \n",
    "    2 **\"description\"**: A brief summary of the document based on the first page without explicit version-naming.\n",
    "    - Summarize the content in 1-3 sentences.  \n",
    "    - **IMPORTANT: Preserve the original language of the document.** If the document is in Indonesian, write the description in Indonesian. If it's in English, write in English.\n",
    "    - If no meaningful description is available, return `\"unknown\"`.\n",
    "    \n",
    "    **Note:** Version will be extracted from the filename automatically, so you don't need to extract it.\n",
    " \n",
    "    **Output format (JSON example):**  \n",
    "    ```json\n",
    "    {\n",
    "        \"topic\": \"Node.js Assertion Module\",\n",
    "        \"description\": \"The document provides information about the assert module in Node.js, detailing its functions and strict assertion mode, including examples of usage and error messaging.\"\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    max_attempts = 5\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            first_page_response = llm_client.generate(system_prompt=system_prompt_first_page, user_prompt=first_page_content)\n",
    "\n",
    "            # Convert JSON string to a Python dictionary\n",
    "            first_page_response = first_page_response.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            data = json.loads(first_page_response)\n",
    "            # Version is no longer extracted from LLM, it comes from filename\n",
    "            # So we don't need to check for version field\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"error during extraction: {e}\")\n",
    "            if attempt >= max_attempts:\n",
    "                raise ValueError(f\"Error: failed to parse llm response:\\n response: {first_page_response}\\n input:{first_page_content}\")\n",
    "    raise ValueError(f\"unable to extract attributes from first page\\n first page: {first_page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddf4d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file_type_from_pages(pages_content):\n",
    "    system_prompt_file_type = \"\"\"\n",
    "    You are an intelligent assistant specialized in analyzing document content.\n",
    "\n",
    "    You will receive the first few chunks of a document (representing its beginning). Your task is to determine whether the document is a **changelog** or a general document.\n",
    "\n",
    "    Return **only** a valid JSON object in the following format:  \n",
    "    { \"answer\": 1 } or { \"answer\": 2 }\n",
    "\n",
    "    ### Classification rules:\n",
    "\n",
    "    1. **1** = WithoutChangelog  \n",
    "        → The document does **not** contain a changelog in the provided chunks.  \n",
    "        → These are general documents (e.g., manuals, specifications, reports) **without** a focus on version updates or modifications.  \n",
    "        → Even if the document mentions changes or has some update history, **if it is not focused on listing changes**, classify it as **1**.\n",
    "\n",
    "    2. **2** = Changelog  \n",
    "        → The document **is a changelog** or **release/update log**.  \n",
    "        → It is specifically focused on listing **changes**, updates, or version history. It includes terms like `Change`, `Revision`, `Modification`, `Amendment`, `Update`, etc.  \n",
    "        → The document must be **dedicated to listing changes** and not just mention them casually.\n",
    "\n",
    "    ### Notes:\n",
    "    - Use only the given text chunks to make your decision.\n",
    "    - If the type is unclear or you're unsure, return **1** as a safe default.\n",
    "    - Return **only** the JSON object – no extra text or formatting.\n",
    "    \"\"\"\n",
    "    max_attempts = 5\n",
    "\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            response = llm_client.generate(system_prompt=system_prompt_file_type, user_prompt=pages_content)\n",
    "            data = json.loads(response) \n",
    "            answer = data.get(\"answer\")\n",
    "            if answer is not None and str(answer).isdigit():\n",
    "                return FileType(int(answer))\n",
    "        except (json.JSONDecodeError, KeyError, ValueError) as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "\n",
    "    raise ValueError('Unable to extract file type from file')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f0499ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract attributes from file ../../../../data/raw/kalender-akademik/2024-2025.pdf\n",
      "page count 9\n",
      "3115\n",
      "2542\n",
      "Extracted version from filename: 2024-2025\n",
      "File: ../../../../data/raw/kalender-akademik/2024-2025.pdf\n",
      "File Type: WithoutChangelog\n",
      "Documentation: Kalender Akademik Universitas Pertamina\n",
      "Display Name: Kalender Akademik Universitas Pertamina\n",
      "Category: kalender-akademik\n",
      "Description: Dokumen ini tentang penetapan Kalender Akademik Universitas Pertamina Tahun Akademik 2024/2025 untuk menjamin pelaksanaan kegiatan pembelajaran yang lancar dan tertib.\n",
      "Version: 2024-2025\n",
      "Additional Attributes:\n",
      "  - None\n"
     ]
    }
   ],
   "source": [
    "# Ekstrak atribut dari file\n",
    "attributes = extract_attributes_from_file(\"../../../../data/raw/kalender-akademik/2024-2025.pdf\")\n",
    "print(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7741db7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract attributes from file ../../../../data/raw/kalender-akademik/2025-2026.pdf\n",
      "page count 10\n",
      "3113\n",
      "2615\n",
      "Extracted version from filename: 2025-2026\n",
      "File: ../../../../data/raw/kalender-akademik/2025-2026.pdf\n",
      "File Type: WithoutChangelog\n",
      "Documentation: Kalender Akademik Universitas Pertamina\n",
      "Display Name: Kalender Akademik Universitas Pertamina\n",
      "Category: kalender-akademik\n",
      "Description: Dokumen ini tentang Surat Keputusan Rektor Universitas Pertamina mengenai Kalender Akademik Universitas Pertamina Tahun Akademik 2025/2026, yang menjamin pelaksanaan kegiatan pembelajaran dapat dilaksanakan dengan lancar dan tertib.\n",
      "Version: 2025-2026\n",
      "Additional Attributes:\n",
      "  - None\n"
     ]
    }
   ],
   "source": [
    "# Ekstrak atribut dari file\n",
    "attributes2 = extract_attributes_from_file(\"../../../../data/raw/kalender-akademik/2025-2026.pdf\")\n",
    "print(attributes2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
