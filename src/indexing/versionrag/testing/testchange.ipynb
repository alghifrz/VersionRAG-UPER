{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "682e5a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../../../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89924f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from util.llm_client import LLMClient\n",
    "from util.chunker import Chunker, Chunk\n",
    "import json\n",
    "from pdfminer.high_level import extract_text\n",
    "from deepdiff import DeepDiff\n",
    "import time\n",
    "import re\n",
    "\n",
    "llm_client = LLMClient(json_format=True, temp=0.0)\n",
    "chunker = Chunker()\n",
    "\n",
    "class ChangeOrigin(Enum):\n",
    "    Extraction = 1\n",
    "    Differ = 2\n",
    "    \n",
    "# class Change:\n",
    "#     def __init__(self, documentation: str, version: str, name: str, description: str, source_file: str, source_page_nr: int, origin: ChangeOrigin):\n",
    "#         self.documentation = documentation\n",
    "#         self.version = version\n",
    "#         self.name = name\n",
    "#         self.description = description\n",
    "#         self.source_file = source_file\n",
    "#         self.source_page_nr = source_page_nr\n",
    "#         self.origin = origin\n",
    "#     def __repr__(self):\n",
    "#         return (\n",
    "#             f\"Change(documentation='{self.documentation}', \"\n",
    "#             f\"version='{self.version}', \"\n",
    "#             f\"name='{self.name}', \"\n",
    "#             f\"status_origin='{self.origin.name}')\"\n",
    "        # )\n",
    "from util.llm_client import LLMClient\n",
    "from util.chunker import Chunker, Chunk\n",
    "\n",
    "\n",
    "# =========================\n",
    "# INIT\n",
    "# =========================\n",
    "\n",
    "llm_client = LLMClient(json_format=True, temp=0.0)\n",
    "chunker = Chunker()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# DATA MODEL\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class Change:\n",
    "    documentation: str\n",
    "    version: str\n",
    "    name: str\n",
    "    description: str\n",
    "    source_file: str\n",
    "    source_page_nr: int\n",
    "    origin: ChangeOrigin\n",
    "\n",
    "def extract_changes_from_changelog(changelog_content) -> list[Change]:\n",
    "    system_prompt=\"\"\"\n",
    "                   You are an assistant. Extract structured changes from changelog text chunks.\n",
    "\n",
    "                    - Return a JSON object with a key \"changes\" (an array).\n",
    "                    - Each change must have:\n",
    "                    - \"name\": short title (string)\n",
    "                    - \"description\": detailed explanation including any ticket numbers or IDs from the text (string)\n",
    "                    - Use the original language.\n",
    "                    - If no changes are found, return: { \"changes\": [] }\n",
    "                    - Return only a valid JSON object. Do not include any other text, explanation, or formatting.\n",
    "\n",
    "                    Example:\n",
    "                    {\n",
    "                    \"changes\": [\n",
    "                        {\n",
    "                        \"name\": \"Login Retry Updated\",\n",
    "                        \"description\": \"The login retry logic now includes exponential backoff and lockout timing (Ticket #12345).\"\n",
    "                        },\n",
    "                        {\n",
    "                        \"name\": \"Encryption Standards Added\",\n",
    "                        \"description\": \"New section for encryption standards introduced, including AES-256 and RSA (ID-4567).\"\n",
    "                        }\n",
    "                    ]\n",
    "                    }\n",
    "                                   \"\"\"\n",
    "    changelog_file = changelog_content[\"file\"]\n",
    "    chunks = chunker.chunk_document(data_file=changelog_file)\n",
    "    def merge_chunks(chunks, group_size=2):\n",
    "        merged_texts = []\n",
    "        for i in range(0, len(chunks), group_size):\n",
    "            group = chunks[i:i + group_size]\n",
    "            merged = \"\\n\\n\".join(chunk.chunk for chunk in group)\n",
    "            merged_texts.append(merged)\n",
    "        return merged_texts\n",
    "    chunks = merge_chunks(chunks)\n",
    "    # formatted_chunks_per_page = group_chunks_per_page(chunks=chunks)\n",
    "    # todo: withChangelog content is probably way too much.. prework needed (what pages are interesting... or only first 10 pages?)\n",
    "    # todo: json format nicht ganz zuverlässig, zu csv wechseln maybe?\n",
    "    print(f\"generate changes from changelog {changelog_file}\")\n",
    "    print(f\"groups count {len(chunks)}\")\n",
    "    extracted_changes_raw = []\n",
    "    max_attempts = 3\n",
    "    for chunk in chunks:\n",
    "        for attempt in range(max_attempts):\n",
    "            try:\n",
    "                response = llm_client.generate(system_prompt=system_prompt, user_prompt=chunk)\n",
    "                response = response.replace(\"```json\", \"\").replace(\"```\", \"\").replace(\"\\n\", \"\").strip()\n",
    "                data = json.loads(response)\n",
    "                extracted_changes_raw_page = data.get(\"changes\", [])\n",
    "                extracted_changes_raw.extend(extracted_changes_raw_page)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"failed: {e}\")\n",
    "                if attempt >= max_attempts - 1:\n",
    "                    raise ValueError(f\"Error: failed to parse llm response:\\n response: {response}\")\n",
    "    \n",
    "    extracted_changes = []\n",
    "    for extracted_change_raw in extracted_changes_raw:\n",
    "        page_number = -1\n",
    "        if hasattr(extracted_change_raw, \"page_number\"):\n",
    "            page_number = extracted_change_raw[\"page_number\"]\n",
    "                \n",
    "        extracted_changes.append(Change(documentation=changelog_content[\"documentation\"],\n",
    "                                        version=changelog_content[\"version\"],\n",
    "                                        name=extracted_change_raw[\"name\"],\n",
    "                                        description=extracted_change_raw[\"description\"],\n",
    "                                        source_file=changelog_content[\"file\"],\n",
    "                                        source_page_nr=page_number,\n",
    "                                        origin=ChangeOrigin.Extraction\n",
    "                                        ))\n",
    "    return extracted_changes\n",
    "\n",
    "\n",
    "# todo: put into own py file\n",
    "def _normalize_text_for_diff(text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Normalize text before running DeepDiff so that purely formatting-related\n",
    "    differences (whitespace, blank lines, minor spacing) are minimized.\n",
    "\n",
    "    - Strip leading/trailing whitespace\n",
    "    - Collapse multiple internal whitespace into a single space\n",
    "    - Drop empty lines\n",
    "    \"\"\"\n",
    "    lines = text.splitlines()\n",
    "    normalized_lines = []\n",
    "    for line in lines:\n",
    "        # Trim leading/trailing whitespace\n",
    "        stripped = line.strip()\n",
    "        if not stripped:\n",
    "            # Drop completely empty / whitespace-only lines\n",
    "            continue\n",
    "        # Collapse multiple spaces/tabs into single space\n",
    "        collapsed = re.sub(r\"\\s+\", \" \", stripped)\n",
    "        normalized_lines.append(collapsed)\n",
    "    return normalized_lines\n",
    "\n",
    "\n",
    "def generate_changes_from_diff(contents_to_diff) -> list[Change]:\n",
    "    system_prompt = \"\"\"You are an intelligent assistant tasked with creating a structured and comprehensive change log based on a list of document changes.\n",
    "\n",
    "                        ### Your Role:\n",
    "                        - Extract and structure **only meaningful content changes** such as:\n",
    "                        - Added, removed, or modified **fields**, **sections**, or **values**\n",
    "                        - Substantial text edits (e.g., reworded definitions, updated parameter values)\n",
    "                        - **Ignore non-substantive changes**, including:\n",
    "                        - Layout, formatting, style, punctuation, page numbers, font, and spacing\n",
    "                        - Header capitalization, whitespace or markdown syntax changes that don’t affect meaning\n",
    "\n",
    "                        ### Language and Style:\n",
    "                        - Always return output in the **original language** of the input.\n",
    "                        - Your descriptions must be **clear, complete, and precise**.\n",
    "                        - If fields or parameters are added/removed/modified, **explicitly list them all.**\n",
    "                        - Do not summarize or use vague terms like \"etc.\" or \"various fields\"\n",
    "                        - Specify: field names, their types, default values, and descriptions, if available\n",
    "                        - If multiple items changed, separate them clearly\n",
    "\n",
    "                        ### Output Rules:\n",
    "                        - If **no relevant content changes** are found, return an empty list: `[]`\n",
    "                        - Each meaningful change should include:\n",
    "                        - `\"name\"`: A short, specific title summarizing the change\n",
    "                        - `\"description\"`: A detailed explanation of exactly what changed, including field names and values if applicable\n",
    "                        - `\"status\"`: One of `\"added\"`, `\"removed\"`, or `\"modified\"`\n",
    "\n",
    "                        ### Output Format:\n",
    "                        ```json\n",
    "                        {\n",
    "                        \"changes\": [\n",
    "                            {\n",
    "                            \"name\": \"New Logging Fields Added\",\n",
    "                            \"description\": \"Added the following fields to the logging configuration section:\\n- logLevel <string> Default: 'info' – Specifies the logging verbosity.\\n- logToFile <boolean> Default: false – Enables file logging.\\n- logFilePath <string> – Path where the log file is written.\",\n",
    "                            \"status\": \"added\"\n",
    "                            },\n",
    "                            {\n",
    "                            \"name\": \"Removed Deprecated Parameters\",\n",
    "                            \"description\": \"Removed these deprecated fields from the API config:\\n- enableBetaMode <boolean>\\n- useLegacyCache <boolean>\",\n",
    "                            \"status\": \"removed\"\n",
    "                            },\n",
    "                            {\n",
    "                            \"name\": \"Updated Timeout Defaults\",\n",
    "                            \"description\": \"Modified default values for the following fields:\\n- requestTimeout: changed from 30s to 60s\\n- retryInterval: changed from 5s to 10s\",\n",
    "                            \"status\": \"modified\"\n",
    "                            }\n",
    "                        ]\n",
    "                        }\n",
    "                        \"\"\"\n",
    "\n",
    "    def read_file_content(filepath):\n",
    "        if filepath.lower().endswith(\".pdf\"):\n",
    "            return extract_text(filepath)\n",
    "        else:\n",
    "            with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "                return f.read()\n",
    " \n",
    "    extracted_changes = []\n",
    "    for content_to_diff in contents_to_diff:\n",
    "        print(\"generate changes from diff\")\n",
    "\n",
    "        file1 = content_to_diff[\"file1\"]\n",
    "        file2 = content_to_diff[\"file2\"]\n",
    "\n",
    "        file1_content = read_file_content(file1)\n",
    "        file2_content = read_file_content(file2)\n",
    "\n",
    "        # Normalize text to reduce noise from formatting-only changes\n",
    "        file1_lines = _normalize_text_for_diff(file1_content)\n",
    "        file2_lines = _normalize_text_for_diff(file2_content)\n",
    "\n",
    "        diff = DeepDiff(file1_lines, file2_lines, verbose_level=2, ignore_order=True)\n",
    "\n",
    "        # If there is no actual difference after normalization, skip this pair\n",
    "        if not diff:\n",
    "            print(\"No meaningful diff detected after normalization, skipping change generation for this pair.\")\n",
    "            continue\n",
    "\n",
    "        diff_json = diff.to_json(indent=2)\n",
    "        max_attempts = 3\n",
    "        for attempt in range(max_attempts):\n",
    "            try:\n",
    "                response = llm_client.generate(system_prompt=system_prompt, user_prompt=diff_json)\n",
    "                response = response.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "                data = json.loads(response)\n",
    "                extracted_changes_raw = data.get(\"changes\", [])\n",
    "                if extracted_changes_raw:\n",
    "                    extracted_changes.extend(extract_generated_changes_from_output(content_to_diff, extracted_changes_raw))\n",
    "                break\n",
    "            except:\n",
    "                print(f\"Error parsing JSON (Attempt {attempt+1}/3).\")\n",
    "                time.sleep(1)  # small delay for next request\n",
    "    return extracted_changes\n",
    "\n",
    "def extract_generated_changes_from_output(content_to_diff, extracted_changes_raw):    \n",
    "    extracted_changes = []\n",
    "    for extracted_change_raw in extracted_changes_raw:\n",
    "        extracted_changes.append(Change(documentation=content_to_diff[\"documentation\"],\n",
    "                                version=content_to_diff[\"version2\"],\n",
    "                                name=extracted_change_raw[\"name\"],\n",
    "                                description=extracted_change_raw[\"description\"],\n",
    "                                source_file=content_to_diff[\"file2\"],\n",
    "                                source_page_nr=-1,\n",
    "                                origin=ChangeOrigin.Differ\n",
    "                                ))\n",
    "    return extracted_changes\n",
    "\n",
    "def group_chunks_per_page(chunks: list[Chunk]):\n",
    "    chunks.sort(key=lambda x: x.page)\n",
    "    results = []\n",
    "    results_page = []\n",
    "    current_page = None\n",
    "    for chunk in chunks:\n",
    "        if chunk.page != current_page:\n",
    "            if current_page is not None:\n",
    "                results.append(f\"\\nPage {current_page}\\n\" + \"\\n\".join(content for content in results_page))\n",
    "            results_page = []\n",
    "            current_page = chunk.page\n",
    "        results_page.append(chunk.chunk)\n",
    "    if current_page and len(results_page) > 0:\n",
    "        results.append(f\"\\nPage {current_page}\\n\" + \"\\n\".join(content for content in results_page))\n",
    "    return results\n",
    "\n",
    "# =============================\n",
    "# EXAMPLE USAGE\n",
    "# =============================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee679ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate changes from diff\n",
      "20184\n"
     ]
    }
   ],
   "source": [
    "    diff_contents = [\n",
    "        {\n",
    "            'documentation': 'Kalender Akademik',\n",
    "            'version1': '2024-2025',\n",
    "            'file1': '../../../../data/raw/kalender-akademik/2024-2025.pdf',\n",
    "            # 'file1': '../../../util/2024_akademik_chunks_data.json',\n",
    "            'version2': '2025-2026',\n",
    "            'file2': '../../../../data/raw/kalender-akademik/2025-2026.pdf'\n",
    "            # 'file2': '../../../util/2025_akademik_chunks_data.json'\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    changes = generate_changes_from_diff(diff_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9764b763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change(documentation='Kalender Akademik', version='2025-2026', name='Tahun Akademik Update', description='Tahun akademik diubah dari 2024/2025 menjadi 2025/2026', source_file='../../../../data/raw/kalender-akademik/2025-2026.pdf', source_page_nr=-1, origin=<ChangeOrigin.Differ: 2>)\n",
      "Change(documentation='Kalender Akademik', version='2025-2026', name='Nomor Keputusan Update', description='Nomor keputusan diubah dari 0103/UPER-R/SK/HK.01/VI/2024 menjadi 234/UPER-R/SK/HK.01/VI/2025', source_file='../../../../data/raw/kalender-akademik/2025-2026.pdf', source_page_nr=-1, origin=<ChangeOrigin.Differ: 2>)\n",
      "Change(documentation='Kalender Akademik', version='2025-2026', name='Perwalian dan Pengisian KRS Update', description='Perwalian ke-1 dan pengisian KRS oleh mahasiswa diubah dari 10 Januari menjadi 15 September', source_file='../../../../data/raw/kalender-akademik/2025-2026.pdf', source_page_nr=-1, origin=<ChangeOrigin.Differ: 2>)\n",
      "Change(documentation='Kalender Akademik', version='2025-2026', name='Pengajuan Perubahan Rencana Studi (PRS) Update', description='Pengajuan PRS oleh mahasiswa diubah dari 23 September menjadi 22 September', source_file='../../../../data/raw/kalender-akademik/2025-2026.pdf', source_page_nr=-1, origin=<ChangeOrigin.Differ: 2>)\n",
      "Change(documentation='Kalender Akademik', version='2025-2026', name='Persetujuan Perubahan Rencana Studi (PRS) Update', description='Persetujuan PRS oleh dosen diubah dari 2 Oktober menjadi 9 Oktober', source_file='../../../../data/raw/kalender-akademik/2025-2026.pdf', source_page_nr=-1, origin=<ChangeOrigin.Differ: 2>)\n",
      "Change(documentation='Kalender Akademik', version='2025-2026', name='Masa Perkuliahan Semester Ganjil Update', description='Masa perkuliahan semester ganjil diubah dari 18 Agustus menjadi 9 Januari 2026', source_file='../../../../data/raw/kalender-akademik/2025-2026.pdf', source_page_nr=-1, origin=<ChangeOrigin.Differ: 2>)\n",
      "Change(documentation='Kalender Akademik', version='2025-2026', name='Masa Perkuliahan Semester Genap Update', description='Masa perkuliahan semester genap diubah dari 10 Februari menjadi 26 April', source_file='../../../../data/raw/kalender-akademik/2025-2026.pdf', source_page_nr=-1, origin=<ChangeOrigin.Differ: 2>)\n",
      "Change(documentation='Kalender Akademik', version='2025-2026', name='Batas Waktu Pengumuman Nilai UTS Update', description='Batas waktu pengumuman nilai UTS diubah dari 18 November menjadi 21 November', source_file='../../../../data/raw/kalender-akademik/2025-2026.pdf', source_page_nr=-1, origin=<ChangeOrigin.Differ: 2>)\n",
      "Change(documentation='Kalender Akademik', version='2025-2026', name='Batas Waktu Pengumuman Nilai UAS Update', description='Batas waktu pengumuman nilai UAS diubah dari 15 Februari menjadi 26 Februari', source_file='../../../../data/raw/kalender-akademik/2025-2026.pdf', source_page_nr=-1, origin=<ChangeOrigin.Differ: 2>)\n",
      "Change(documentation='Kalender Akademik', version='2025-2026', name='Yudisium Universitas Update', description='Yudisium universitas ke-1 diubah dari 20 Januari menjadi 23 Januari', source_file='../../../../data/raw/kalender-akademik/2025-2026.pdf', source_page_nr=-1, origin=<ChangeOrigin.Differ: 2>)\n",
      "Change(documentation='Kalender Akademik', version='2025-2026', name='Wisuda Ke-1 Update', description='Wisuda ke-1 diubah dari 25 Juni menjadi 27 Oktober', source_file='../../../../data/raw/kalender-akademik/2025-2026.pdf', source_page_nr=-1, origin=<ChangeOrigin.Differ: 2>)\n",
      "Change(documentation='Kalender Akademik', version='2025-2026', name='Wisuda Ke-2 Update', description='Wisuda ke-2 diubah dari 28 Oktober menjadi 27 Oktober', source_file='../../../../data/raw/kalender-akademik/2025-2026.pdf', source_page_nr=-1, origin=<ChangeOrigin.Differ: 2>)\n"
     ]
    }
   ],
   "source": [
    "    for c in changes:\n",
    "        print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
